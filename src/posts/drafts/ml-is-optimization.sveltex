---
title: "Machine Learning Isn't Magic; It's Just Optimization"
date: "2026-01-30"
description: "Machine learning demystified: at its core, it's just finding the minimum of a function."
tags: ["machine-learning", "optimization"]
draft: true
---

Instead of caring about all of the machine learning models and techniques, I want to go through the first principles of how you can derive the idea of machine learning.
Some problems seem intractable in computer science, like programmatically identifying if an image shows a dog or not.
If you knew nothing about machine learning, it's hard to imagine where you'd even start.

On the other hand, there are far simpler problems that we do know how to solve.
So it makes sense to start with a simple problem we can solve and gradually make it harder to turn it into the difficult problem we want to solve.

## Optimizing a Quadratic Polynomial

Say you're running a business and want to maximize your revenue selling a product.
You notice a relationship where if you price the product at $p$ dollars, you can sell $100 - 2p$ units.
Now you want to find the value of $p$ that maximizes your revenue $R(p) = p(100 - 2p) = -2p^2 + 100p$.

![R(p) = p(100 − 2p)](/images/posts/ml-is-optimization/revenue.png)

There are multiple approaches you could use to maximize a simple quadratic polynomial.
One way is to complete the square and rewrite $R(p)$ as $-2(p - 25)^2 + 1250$ which is maximized at $R(25) = 1250$ because the first term being a negative squared value is always nonpositive.

A more general purpose approach is to find the critical points, which you get when you set the derivative to $0$, and then find the critical point that maximizes the function.
In this case, $R'(p) = -4p + 100 = 0 \implies p = 25$ is the only critical point.

An even more general purpose approach for when you can't solve for the derivative being $0$ is to start at a random point and traverse along the gradient.
This is called gradient ascent when maximizing a function and gradient descent when minimizing a function.
This is useful for finding local maximums and minimums of a function, and in the case of a function being concave or convex, the local maximum or minimum are also the global maximum or minimum.

The update rule for gradient ascent is $p_{n+1} = p_n + \alpha R'(p_n)$, where $\alpha$ is the step size.
Since $R'(p) = -4p + 100$, let's start at $p_0 = 5$ with $\alpha = 0.1$ and see what happens:

$$
\begin{aligned}
p_0 &= 5.00 & R'(p_0) &= 80.0 & R(p_0) &= 450 \\
p_1 &= 5 + 0.1 \cdot 80 = 13.00 & R'(p_1) &= 48.0 & R(p_1) &= 962 \\
p_2 &= 13 + 0.1 \cdot 48 = 17.80 & R'(p_2) &= 28.8 & R(p_2) &= 1146 \\
p_3 &= 17.8 + 0.1 \cdot 28.8 = 20.68 & R'(p_3) &= 17.3 & R(p_3) &= 1213 \\
p_4 &= 20.68 + 0.1 \cdot 17.3 = 22.41 & R'(p_4) &= 10.4 & R(p_4) &= 1237 \\
p_5 &= 22.41 + 0.1 \cdot 10.4 = 23.44 & R'(p_5) &= 6.2 & R(p_5) &= 1245
\end{aligned}
$$

Each step moves $p$ in the direction of increasing $R$, and the steps get smaller as the gradient shrinks near the peak.
After just a few iterations $p$ is close to $25$ and $R(p)$ is almost $1250$.

![Gradient ascent on R(p)](/images/posts/ml-is-optimization/gradient-ascent.png)

Now let's move on to a more complex function.

## Optimizing a Single Variable Function

<!-- TODO: generalize beyond quadratics to an arbitrary f(x) where analytic
     solutions aren't available. Introduce gradient descent here:
     x_{n+1} = x_n - α f'(x_n). Walk through steps numerically on a simple
     example. Show different learning rates (too small, too large, just right).
     This is the key bridge from "calculus we know" to "iterative methods ML
     actually uses." -->

## Optimizing a Two Variable Function

<!-- TODO: extend to f(x, y). Gradient is now a vector, update rule is the
     same. Contour plot with descent path. Key point: nothing conceptually
     changed, just more parameters. "Now imagine a million parameters." -->

## Creating a Simple Model

This is where we stop going over introductory calculus concepts and shift the focus to machine learning.

<!-- TODO: bridge from optimization to ML. Start with a tiny dataset and a
     model (e.g. linear regression with slope/intercept). Define error as a
     function of the model parameters — this is the "loss." Show that the loss
     is just another function to minimize, exactly like the ones above.
     The image classification example (function that takes an image and says
     if it contains a dog or not) may be too big a jump here — consider
     starting with something simpler and mentioning images as where this
     scales to. -->

## Creating a Slightly Better Model

<!-- TODO: iterate on the simple model. Maybe go from a line to a curve, or
     add a feature. Show that "better model" = "different function family to
     optimize over." The optimization machinery stays the same. -->
