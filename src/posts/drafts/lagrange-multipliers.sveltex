---
title: "Lagrange Multipliers"
date: "2026-02-18"
description: "Constrained optimization with Lagrange multipliers"
tags: ["math", "calculus", "optimization"]
---

Calculus-based optimization methods can be summarized in a single sentence: **when minimizing a function, every point either has a nearby point that decreases the function, or is a candidate for minimizing it.**
This can be seen in single variable optimization problems, where we either solve for critical points by setting the derivative of the function equal to $0$, or use the derivative to indicate which direction to move to decrease the function.
In multivariable optimization problems, all nearby points are obtained by small perturbations of each variable.
When the partial derivatives of the function with respect to each variable are $0$, then no nearby point decreases the function.
Otherwise, for each nonzero partial derivative, there is a known direction to perturb the corresponding variable to decrease the function.
Gradient descent does this while also setting the magnitude of the perturbation to be proportional to the partial derivative.

Lagrange multipliers is a method for solving optimization problems subject to constraints on the variables.
For a single constraint, the problem is
$$
\min_{x_1, \ldots, x_n} f(x_1, x_2, \ldots, x_n) \quad \text{subject to} \quad g(x_1, x_2, \ldots, x_n) = 0
$$
Instead of describing the method of Lagrange multipliers, we can reason about the core idea described in the previous paragraph to obtain the same approach to the constrained optimization problem.

Without the constraint, we would ordinarily minimize $f(x_1, x_2, \ldots, x_n)$ by setting $\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \ldots, \frac{\partial f}{\partial x_n}$ to all be $0$.
This is because every point near $(x_1, x_2, \ldots, x_n)$ is of the form $(x_1 + \delta_1, x_2 + \delta_2, \ldots, x_n + \delta_n)$ where all $\delta_k$ are small, and a first-order approximation gives that $f(x_1 + \delta_1, x_2 + \delta_2, \ldots, x_n + \delta_n)$ is approximately $f(x_1, x_2, \ldots, x_n) + \frac{\partial f}{\partial x_1}\delta_1 + \frac{\partial f}{\partial x_2}\delta_2 + \ldots + \frac{\partial f}{\partial x_n}\delta_n$.
If any $\frac{\partial f}{\partial x_k}$ were nonzero, it would be possible to choose the sign of a small $\delta_k$ to make $\frac{\partial f}{\partial x_k} \delta_k$ negative and decrease the function as a result.

The constraint restricts the possible valid perturbations we can make to $(x_1, x_2, \ldots, x_n)$.
If we consider the effect on $g$ of an arbitrary perturbation, we see that $g(x_1 + \delta_1, x_2 + \delta_2, \ldots, x_n + \delta_n)$ is approximately $g(x_1, x_2, \ldots, x_n) + \frac{\partial g}{\partial x_1}\delta_1 + \frac{\partial g}{\partial x_2}\delta_2 + \ldots + \frac{\partial g}{\partial x_n}\delta_n$.
Starting from $g(x_1, x_2, \ldots, x_n) = 0$, valid perturbations that satisfy the constraint must satisfy $\frac{\partial g}{\partial x_1}\delta_1 + \frac{\partial g}{\partial x_2}\delta_2 + \ldots + \frac{\partial g}{\partial x_n}\delta_n = 0$.

Restricting the valid perturbations means there are fewer nearby points to consider. A point is a candidate for minimizing $f$ if none of the valid perturbations can decrease the function.
This means we only require that for any perturbation satisfying $\frac{\partial g}{\partial x_1}\delta_1 + \frac{\partial g}{\partial x_2}\delta_2 + \ldots + \frac{\partial g}{\partial x_n}\delta_n = 0$, $\frac{\partial f}{\partial x_1}\delta_1 + \frac{\partial f}{\partial x_2}\delta_2 + \ldots + \frac{\partial f}{\partial x_n}\delta_n = 0$ must hold.

Notice that these expressions are like dot products if you let $\vec{u} = \nabla f$, $\vec{v} = \nabla g$, and $\vec{\delta} = (\delta_1, \delta_2, \ldots, \delta_n)$, and this requirement can be reinterpreted as: given $\vec{v} \cdot \vec{\delta} = 0$, $\vec{u} \cdot \vec{\delta} = 0$ must hold.
$\vec{\delta}$ is allowed to be any vector orthogonal to $\vec{v}$ (assuming $\vec{v} \neq 0$), and the only vectors that are orthogonal to every vector orthogonal to $\vec{v}$ are scalar multiples of $\vec{v}$.
To see this, decompose $\vec{u}$ into a component along $\vec{v}$ and a component orthogonal to $\vec{v}$: that is, $\vec{u} = \text{proj}_{\vec{v}} \vec{u} + \vec{u}_\perp$.
If $\vec{u}_\perp$ were nonzero, we could choose $\vec{\delta} = \vec{u}_\perp$, which is orthogonal to $\vec{v}$ but — since $\text{proj}_{\vec{v}} \vec{u}$ is along $\vec{v}$ and hence orthogonal to $\vec{u}_\perp$ — gives $\vec{u} \cdot \vec{\delta} = \vec{u}_\perp \cdot \vec{u}_\perp > 0$, a contradiction.
So $\vec{u}_\perp = 0$, meaning $\vec{u}$ must point entirely in the direction of $\vec{v}$: that is, $\nabla f = \lambda \nabla g$ for some scalar $\lambda$.

Translating back, the conditions for a candidate to minimize $f$ subject to the constraint are:
$$
g(x_1, x_2, \ldots, x_n) = 0
$$
$$
\nabla f = \lambda \nabla g
$$
for some scalar $\lambda$.
This is exactly what the method of Lagrange multipliers prescribes, and $\lambda$ is the Lagrange multiplier.
The second condition says that the gradient of $f$ must be proportional to the gradient of $g$ — in other words, the only directions that could decrease $f$ are directions that would violate the constraint.
