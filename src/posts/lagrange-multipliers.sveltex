---
title: "Lagrange Multipliers"
date: "2026-02-19"
description: "Constrained optimization with Lagrange multipliers"
tags: ["math", "calculus", "optimization"]
---

Calculus-based optimization methods can be summarized in a single sentence: **when minimizing a function, every point either has a nearby point that decreases the function, or is a candidate minimum.**
This can be seen in single variable optimization problems, where we either solve for critical points by setting the derivative of the function equal to $0$, or use the derivative to indicate which direction to move to decrease the function.
In multivariable optimization problems, all nearby points are obtained by small perturbations of each variable.
When the partial derivatives of the function with respect to each variable are $0$, then no nearby point decreases the function.
Otherwise, for each nonzero partial derivative, there is a known direction to perturb the corresponding variable to decrease the function.
Gradient descent does this while also setting the magnitude of the perturbation to be proportional to the partial derivative.

Lagrange multipliers is a method for solving optimization problems subject to constraints on the variables.
For a single constraint, the problem is
$$
\min_{x_1, \ldots, x_n} f(x_1, x_2, \ldots, x_n) \quad \text{subject to} \quad g(x_1, x_2, \ldots, x_n) = 0
$$
Instead of describing the method of Lagrange multipliers, we can reason about the core idea described in the first paragraph to obtain the same approach to the constrained optimization problem.

Without the constraint, we would ordinarily minimize $f$ by setting all its partial derivatives to $0$.
This is because every point near $(x_1, x_2, \ldots, x_n)$ is of the form $(x_1 + \delta_1, x_2 + \delta_2, \ldots, x_n + \delta_n)$ for small perturbations $\delta_k$, and a first-order approximation gives
$$
f(x_1 + \delta_1, x_2 + \delta_2, \ldots, x_n + \delta_n) \approx f(x_1, x_2, \ldots, x_n) + \frac{\partial f}{\partial x_1}\delta_1 + \frac{\partial f}{\partial x_2}\delta_2 + \ldots + \frac{\partial f}{\partial x_n}\delta_n
$$
If any $\frac{\partial f}{\partial x_k}$ were nonzero, it would be possible to choose the sign of a small perturbation $\delta_k$ to make $\frac{\partial f}{\partial x_k} \delta_k$ negative and decrease the function as a result.
Setting all partial derivatives to $0$ is equivalent to requiring
$$
\frac{\partial f}{\partial x_1}\delta_1 + \frac{\partial f}{\partial x_2}\delta_2 + \ldots + \frac{\partial f}{\partial x_n}\delta_n = 0
$$
for all perturbations $(\delta_1, \delta_2, \ldots, \delta_n)$.

The constraint gives us $g(x_1, x_2, \ldots, x_n) = 0$ and restricts the valid perturbations we can make to $(x_1, x_2, \ldots, x_n)$.
Since
$$
g(x_1 + \delta_1, x_2 + \delta_2, \ldots, x_n + \delta_n) \approx g(x_1, x_2, \ldots, x_n) + \frac{\partial g}{\partial x_1}\delta_1 + \frac{\partial g}{\partial x_2}\delta_2 + \ldots + \frac{\partial g}{\partial x_n}\delta_n
$$
combining $g(x_1, x_2, \ldots, x_n) = 0$ with the requirement that $g$ remains $0$ after the perturbation gives
$$
\frac{\partial g}{\partial x_1}\delta_1 + \frac{\partial g}{\partial x_2}\delta_2 + \ldots + \frac{\partial g}{\partial x_n}\delta_n = 0
$$

With the constraint, we no longer need
$$
\frac{\partial f}{\partial x_1}\delta_1 + \frac{\partial f}{\partial x_2}\delta_2 + \ldots + \frac{\partial f}{\partial x_n}\delta_n = 0
$$
for all perturbations, only for those satisfying
$$
\frac{\partial g}{\partial x_1}\delta_1 + \frac{\partial g}{\partial x_2}\delta_2 + \ldots + \frac{\partial g}{\partial x_n}\delta_n = 0
$$

These expressions are dot products. Letting
$$
\nabla f = \left(\frac{\partial f}{\partial x_1}, \ldots, \frac{\partial f}{\partial x_n}\right), \quad \nabla g = \left(\frac{\partial g}{\partial x_1}, \ldots, \frac{\partial g}{\partial x_n}\right), \quad \vec{\delta} = (\delta_1, \delta_2, \ldots, \delta_n)
$$
the requirement is that $\nabla f \cdot \vec{\delta} = 0$ for all $\vec{\delta}$ satisfying $\nabla g \cdot \vec{\delta} = 0$.
Since $\vec{\delta}$ can be any vector orthogonal to $\nabla g$, $\nabla f$ must be a scalar multiple of $\nabla g$.

To see this, if $\nabla f$ had any component not along $\nabla g$, that component would itself be orthogonal to $\nabla g$ and so would be a valid choice of $\vec{\delta}$, but dotting it with $\nabla f$ would be positive, contradicting the requirement.
So $\nabla f$ must point entirely along $\nabla g$, meaning $\nabla f = \lambda \nabla g$ for some scalar $\lambda$.

Together with the constraint $g(x_1, x_2, \ldots, x_n) = 0$, the conditions for a candidate minimum are:
$$
g(x_1, x_2, \ldots, x_n) = 0
$$
$$
\nabla f = \lambda \nabla g
$$
for some scalar $\lambda$. This is exactly the method of Lagrange multipliers, where $\lambda$ is the Lagrange multiplier.
The gradient of $f$ must be proportional to the gradient of $g$, meaning the only directions that could decrease $f$ are directions that would violate the constraint.

The same reasoning extends to multiple equality constraints $g_1 = 0, \ldots, g_m = 0$. Valid perturbations must be orthogonal to all $\nabla g_i$, so $\nabla f$ must lie in their span, giving $\nabla f = \lambda_1 \nabla g_1 + \cdots + \lambda_m \nabla g_m$.
It can also be used to derive the [Karush-Kuhn-Tucker (KKT) conditions](https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions), which generalize Lagrange multipliers to inequality constraints.
